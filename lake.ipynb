{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c39dd8454138eeaae7582c1b8b9112000612a2e483c721ee49090cb6d3cfebe8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "source": [
    " `[(transition probability, next state, reward, Is terminal state?)].`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "record=np.zeros([env.observation_space.n])\n",
    "record.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.33333333 0.        ]\n",
      "[0.74612083 0.72042399 0.70220817 0.69276611 0.75177057 0.\n",
      " 0.47426439 0.         0.76265501 0.77797524 0.72457452 0.\n",
      " 0.         0.85000899 0.92439446 0.        ]\n",
      "[0.8168984  0.81467569 0.81309743 0.8122785  0.81738106 0.\n",
      " 0.52467049 0.         0.81831127 0.8196213  0.76125916 0.\n",
      " 0.         0.87957793 0.93973656 0.        ]\n",
      "[0.82296075 0.82277013 0.82263478 0.82256455 0.82300214 0.\n",
      " 0.52900516 0.         0.82308191 0.82319426 0.7644103  0.\n",
      " 0.         0.88211496 0.94105299 0.        ]\n",
      "[0.82348064 0.8234643  0.82345269 0.82344667 0.82348419 0.\n",
      " 0.5293769  0.         0.82349104 0.82350067 0.76468053 0.\n",
      " 0.         0.88233253 0.94116588 0.        ]\n",
      "[0.82352523 0.82352383 0.82352283 0.82352232 0.82352553 0.\n",
      " 0.52940877 0.         0.82352612 0.82352695 0.76470371 0.\n",
      " 0.         0.88235119 0.94117556 0.        ]\n",
      "[0.82352905 0.82352893 0.82352885 0.8235288  0.82352908 0.\n",
      " 0.52941151 0.         0.82352913 0.8235292  0.7647057  0.\n",
      " 0.         0.88235279 0.94117639 0.        ]\n",
      "[0.82352938 0.82352937 0.82352936 0.82352936 0.82352938 0.\n",
      " 0.52941174 0.         0.82352939 0.82352939 0.76470587 0.\n",
      " 0.         0.88235293 0.94117646 0.        ]\n",
      "[0.82352941 0.82352941 0.82352941 0.82352941 0.82352941 0.\n",
      " 0.52941176 0.         0.82352941 0.82352941 0.76470588 0.\n",
      " 0.         0.88235294 0.94117647 0.        ]\n",
      "[0.82352941 0.82352941 0.82352941 0.82352941 0.82352941 0.\n",
      " 0.52941176 0.         0.82352941 0.82352941 0.76470588 0.\n",
      " 0.         0.88235294 0.94117647 0.        ]\n",
      "[0.82352941 0.82352941 0.82352941 0.82352941 0.82352941 0.\n",
      " 0.52941176 0.         0.82352941 0.82352941 0.76470588 0.\n",
      " 0.         0.88235294 0.94117647 0.        ]\n",
      "[0.82352941 0.82352941 0.82352941 0.82352941 0.82352941 0.\n",
      " 0.52941176 0.         0.82352941 0.82352941 0.76470588 0.\n",
      " 0.         0.88235294 0.94117647 0.        ]\n",
      "[0.82352941 0.82352941 0.82352941 0.82352941 0.82352941 0.\n",
      " 0.52941176 0.         0.82352941 0.82352941 0.76470588 0.\n",
      " 0.         0.88235294 0.94117647 0.        ]\n",
      "[0.82352941 0.82352941 0.82352941 0.82352941 0.82352941 0.\n",
      " 0.52941176 0.         0.82352941 0.82352941 0.76470588 0.\n",
      " 0.         0.88235294 0.94117647 0.        ]\n",
      "1372\n"
     ]
    }
   ],
   "source": [
    "record=np.zeros([env.observation_space.n])\n",
    "threshold=1e-16\n",
    "for i in range(5000):\n",
    "    old_record=np.copy(record)\n",
    "    record=np.zeros(record.shape)\n",
    "    for state in range(env.observation_space.n):\n",
    "        Q_values=[]\n",
    "        for action in range(env.action_space.n):\n",
    "            next_rewards=0\n",
    "            for transition in ((env.P[state][action])):\n",
    "                # print(transition)\n",
    "                transition_probability, next_state, reward, Is_terminal_state=transition\n",
    "                # if reward==1:\n",
    "                #     print('here')\n",
    "                #     print(transition)\n",
    "                #     print(state,action)\n",
    "                next_rewards+=transition_probability*(reward+old_record[next_state])\n",
    "            \n",
    "                # record[state]+=transition_probability*reward+np.sum(old_record[next_state])\n",
    "            \n",
    "            Q_values.append(next_rewards)\n",
    "        record[state]=np.max(Q_values)\n",
    "    if(np.sum(np.abs(record-old_record))<threshold):\n",
    "        print(i)\n",
    "        break\n",
    "    if i%100 == 0:\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.82352941, 0.82352941, 0.82352941, 0.82352941, 0.82352941,\n",
       "       0.        , 0.52941176, 0.        , 0.82352941, 0.82352941,\n",
       "       0.76470588, 0.        , 0.        , 0.88235294, 0.94117647,\n",
       "       0.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.82352941, 0.82352941, 0.82352941, 0.82352941, 0.82352941,\n",
       "       0.        , 0.52941176, 0.        , 0.82352941, 0.82352941,\n",
       "       0.76470588, 0.        , 0.        , 0.88235294, 0.94117647,\n",
       "       0.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "source": [
    "policy=np.zeros(env.observation_space.n)\n",
    "for state in range(env.observation_space.n):\n",
    "    temp=[]\n",
    "    for action in range(env.action_space.n):\n",
    "        next_rewards=0\n",
    "        for transition in env.P[state][action]:\n",
    "            transition_probability, next_state, reward, Is_terminal_state=transition\n",
    "            next_rewards+=transition_probability*(reward+record[next_state])\n",
    "        temp.append(next_rewards)\n",
    "    policy[state]=np.argmax(temp)\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 3., 3., 3., 0., 0., 0., 0., 3., 1., 0., 0., 0., 2., 1., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "source": [
    "## display"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### no intuitive"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n4\n4\n4\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n4\n4\n4\n8\n8\n8\n9\n10\n14\n15\n"
     ]
    }
   ],
   "source": [
    "step=0\n",
    "next_state=0\n",
    "while(step<50 and next_state!=15):\n",
    "    step+=1\n",
    "    state=next_state\n",
    "    action=policy[state]\n",
    "    probably=[]\n",
    "    next_states=[]\n",
    "    # next_rewards=0\n",
    "    for transition in env.P[state][action]:\n",
    "                transition_probability, next_state, reward, Is_terminal_state=transition\n",
    "                probably.append(transition_probability)\n",
    "                next_states.append(next_state)\n",
    "    next_state=np.random.choice(next_states,p=probably)\n",
    "    print(next_state)"
   ]
  },
  {
   "source": [
    "### intuitive with api `render()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\nSFFF\nFHFH\n\u001b[41mF\u001b[0mFFH\nHFFG\n  (Up)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\nSFFF\nFHFH\n\u001b[41mF\u001b[0mFFH\nHFFG\n  (Up)\nSFFF\nFHFH\nF\u001b[41mF\u001b[0mFH\nHFFG\n  (Down)\nSFFF\nFHFH\n\u001b[41mF\u001b[0mFFH\nHFFG\n  (Up)\nSFFF\nFHFH\n\u001b[41mF\u001b[0mFFH\nHFFG\n  (Up)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\nSFFF\nFHFH\n\u001b[41mF\u001b[0mFFH\nHFFG\n  (Up)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n  (Left)\nSFFF\n\u001b[41mF\u001b[0mHFH\nFFFH\nHFFG\n  (Left)\nSFFF\nFHFH\n\u001b[41mF\u001b[0mFFH\nHFFG\n  (Up)\nSFFF\nFHFH\n\u001b[41mF\u001b[0mFFH\nHFFG\n  (Up)\nSFFF\nFHFH\n\u001b[41mF\u001b[0mFFH\nHFFG\n  (Up)\nSFFF\nFHFH\nF\u001b[41mF\u001b[0mFH\nHFFG\n  (Down)\nSFFF\nFHFH\n\u001b[41mF\u001b[0mFFH\nHFFG\n  (Up)\nSFFF\nFHFH\nF\u001b[41mF\u001b[0mFH\nHFFG\n  (Down)\nSFFF\nFHFH\nFF\u001b[41mF\u001b[0mH\nHFFG\n  (Left)\nSFFF\nFHFH\nFFFH\nHF\u001b[41mF\u001b[0mG\n  (Down)\nSFFF\nFHFH\nFFFH\nHF\u001b[41mF\u001b[0mG\n  (Down)\nSFFF\nFHFH\nFFFH\nHF\u001b[41mF\u001b[0mG\n  (Down)\nSFFF\nFHFH\nFFFH\nHF\u001b[41mF\u001b[0mG\n  (Down)\nSFFF\nFHFH\nFFFH\nH\u001b[41mF\u001b[0mFG\n  (Right)\nSFFF\nFHFH\nFFFH\nHF\u001b[41mF\u001b[0mG\nafter 68 steps, success at 15\n"
     ]
    }
   ],
   "source": [
    "render=True\n",
    "for _ in range(1):\n",
    "    step=0\n",
    "    state=0\n",
    "    env.reset()\n",
    "    while(step<500 and state!=15):\n",
    "        step+=1\n",
    "        action=policy[state]\n",
    "        next_state,reward,done,info=env.step(int(action))\n",
    "        if done:\n",
    "            if reward==1:\n",
    "                print('after {0:} steps, success at {1:}'.format(step,next_state))\n",
    "            else:\n",
    "                print('after {0:} steps, failed at {1:}'.format(step,next_state))\n",
    "            break\n",
    "        if render:\n",
    "            env.render()\n",
    "        state=next_state\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "after 47 steps, success at 15\nafter 10 steps, success at 15\nafter 31 steps, success at 15\nafter 55 steps, success at 15\nafter 8 steps, success at 15\nafter 47 steps, success at 15\nafter 24 steps, success at 15\nafter 36 steps, success at 15\nafter 69 steps, success at 15\nafter 100 steps, failed at 4\n"
     ]
    }
   ],
   "source": [
    "render=False\n",
    "for _ in range(10):\n",
    "    step=0\n",
    "    state=0\n",
    "    env.reset()\n",
    "    while(step<500 and state!=15):\n",
    "        step+=1\n",
    "        action=policy[state]\n",
    "        next_state,reward,done,info=env.step(int(action))\n",
    "        if done:\n",
    "            if reward==1:\n",
    "                print('after {0:} steps, success at {1:}'.format(step,next_state))\n",
    "            else:\n",
    "                print('after {0:} steps, failed at {1:}'.format(step,next_state))\n",
    "            break\n",
    "        if render:\n",
    "            env.render()\n",
    "        state=next_state\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}